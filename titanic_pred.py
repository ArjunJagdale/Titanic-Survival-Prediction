# -*- coding: utf-8 -*-
"""Titanic_pred.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EPMwHJWMdlgDbLDqRmfBK1YzEc3JJ75X
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, RocCurveDisplay
from sklearn.impute import SimpleImputer
import joblib
import gradio as gr

# Configurations
RANDOM_STATE = 42
TEST_SIZE = 0.2
MODEL_PATH = "titanic_model.joblib"

"""### Dataset exploration"""

# Data loading and little exploration
url = "https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
df = pd.read_csv(url)

# first few rows
df.head()

# columns and datatype
df.info()

# statistical analysis of data
df.describe()

# shape of dataset
df.shape

# null values from dataset
df.isnull().sum()

# Survival rate
((df['Survived'].mean()) * 100).round(2)

"""### Data Processing"""

"""
Here we need only columns [Pclass, sex, age, sibsp, parch, fare and embarked] for prediction
So avoiding the column cabin even though it has 100's missing values
"""
features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']

df = df.dropna(subset=['Embarked'])

# assigning X and y features
X = df[features]
y = df['Survived']

X.head(10)

y.head(10)

"""### Train-test-split"""

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size = TEST_SIZE, random_state = RANDOM_STATE, stratify = y
)

print("Train size:", X_train.shape)
print("Test size :", X_test.shape)

"""***Tiny visual intuition of stratify***

Imagine 10 samples:

```
Survived:     4
Not survived: 6
```


Without stratify (random):
```
Train: 1 survived, 5 not
Test:  3 survived, 1 not  âŒ
```

With stratify:
```
Train: 3 survived, 5 not
Test:  1 survived, 1 not  
```

### Building Processing pipeline
"""

"""Building a processing pipeline"""

# Impute Numeric features with mean and then scale them!
numeric_features = ['Age', 'Fare', 'SibSp', 'Parch']
numeric_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

"""Why these features?

- Age - Continuous (0-80 years)
- Fare - Continuous ticket price (highly variable: Â£0-Â£512)
- SibSp - Count of siblings/spouses (0-8)
- Parch - Count of parents/children (0-6)

Step 1: SimpleImputer(strategy='median')

- What it does: Fills missing values (mainly Age has 177 nulls)
- Why median? More robust than mean - not affected by extreme outliers (like very old passengers or very high fares)
- Example: If Age has nulls, fills them with ~28 (median age)

Step 2: StandardScaler()

- What it does: Transforms features to have mean=0, std=1
- Why? Features have very different scales:

  - Age: 0-80
  - Fare: 0-512
  - SibSp: 0-8


- Math: scaled_value = (value - mean) / std_deviation
- Why it matters: Many algorithms (though not Random Forest) are sensitive to scale. It's still good practice and allows model comparison later.

"""

# Impute Categorical featurs with mode and then one-hot encode them!
categorical_features = ['Pclass', 'Sex', 'Embarked']
categorical_transformer = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))
])

"""**Why these features?**
- **Pclass** - Passenger class (1=First, 2=Second, 3=Third) - proxy for wealth
- **Sex** - Male/Female - critical predictor (women had priority in lifeboats)
- **Embarked** - Port of embarkation (C=Cherbourg, Q=Queenstown, S=Southampton)

**Step 1: SimpleImputer(strategy='most_frequent')**
- **What it does:** Fills missing values with the most common category
- **Why most_frequent?** Can't use mean/median for text categories
- **Example:** Embarked has 2 nulls â†’ fills with 'S' (Southampton, the most common)

**Step 2: OneHotEncoder(drop='first', handle_unknown='ignore')**
- **What it does:** Converts categories to binary columns

**Example transformation:**
```
Sex: ['male', 'female', 'male']
â†’ Sex_male: [1, 0, 1]
```

**Why drop='first'?**

- Avoids dummy variable trap (multicollinearity)
- If you have Sex_male and Sex_female, they're perfectly correlated:

  - Sex_male=1 always means Sex_female=0
  - This creates redundancy


- With drop='first': Keep only Sex_male (0=female, 1=male)

- Why handle_unknown='ignore'?

  - If new data has unseen categories (e.g., Embarked='T'), don't crash
  - Creates all-zeros for that sample
  - Production safety: Model won't break on unexpected data


"""

# Combine transformer
preprocessor = ColumnTransformer([
    ('num', numeric_transformer, numeric_features),
    ('cat', categorical_transformer, categorical_features)
])

"""**What it does:**
- Applies different transformations to different column types **simultaneously**
- Combines results into one feature matrix

**Visual representation:**
```
Input DataFrame:
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Age â”‚Fare â”‚Pclassâ”‚  Sex   â”‚Embarked â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 22  â”‚ 7.25â”‚  3  â”‚ male   â”‚    S    â”‚
â”‚ NaN â”‚ 71  â”‚  1  â”‚ female â”‚    C    â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After ColumnTransformer:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Age_std â”‚Fare_stdâ”‚SibSp â”‚Parch â”‚Pclass_2  â”‚Pclass_3  â”‚Sex_male â”‚Embarked_Qâ”‚...
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ -0.53  â”‚ -0.50  â”‚  0   â”‚  0   â”‚    0     â”‚    1     â”‚    1    â”‚    0    â”‚
â”‚  0.64  â”‚  0.79  â”‚  1   â”‚  0   â”‚    0     â”‚    0     â”‚    0    â”‚    0    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

# Full pipeline with model
model = Pipeline(steps = [
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(class_weight="balanced",n_estimators=100, max_depth=10, min_samples_split=5, min_samples_leaf=2,random_state=RANDOM_STATE))
])

model

"""### Model training"""

print("training model....")
model.fit(X_train, y_train)
print("training complete....")

"""### Model evaluation"""

y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

print("Classification Report")
print(classification_report(y_test, y_pred, target_names=["Did not survive", "Survived"]))

roc_auc = roc_auc_score(y_test, y_prob)
print(f"ROC-AUC score: {roc_auc}")

RocCurveDisplay.from_predictions(y_test, y_prob)
plt.title("ROC Curve - Titanic Survival Prediction")
plt.grid(alpha=0.3)
plt.show()

"""### Save model + export predictions"""

joblib.dump(model, MODEL_PATH)
print(f"Model saved as {MODEL_PATH}")

predictions_df = pd.DataFrame({
    "True_Label": y_test.values,
    "Predicted":y_pred,
    "Survival_Prob":y_prob
})

predictions_df.to_csv("pred.csv", index=False)
print("CSV exported")

"""### Simple Gradio Inference"""

def predict_survival(Pclass, Sex, Age, SibSp, Parch, Fare, Embarked):
    sample = pd.DataFrame([{
        "Pclass": Pclass,
        "Sex": Sex,
        "Age": Age,
        "SibSp": SibSp,
        "Parch": Parch,
        "Fare": Fare,
        "Embarked": Embarked
    }])

    pred = model.predict(sample)[0]
    prob = model.predict_proba(sample)[0][1]

    label = "âœ… Survived" if pred == 1 else "âŒ Did Not Survive"
    return f"{label}\nSurvival Probability: {prob:.2%}"

demo = gr.Interface(
    fn=predict_survival,
    inputs=[
        gr.Dropdown([1, 2, 3], value=3, label="Passenger Class"),
        gr.Radio(["male", "female"], value="male", label="Sex"),
        gr.Slider(0, 80, value=30, label="Age"),
        gr.Slider(0, 8, value=0, step=1, label="Siblings / Spouses"),
        gr.Slider(0, 6, value=0, step=1, label="Parents / Children"),
        gr.Slider(0, 512, value=32, label="Fare"),
        gr.Dropdown(["C", "Q", "S"], value="S", label="Embarked")
    ],
    outputs=gr.Textbox(label="Prediction"),
    title="ğŸš¢ Titanic Survival Predictor",
    description="Simple ML inference demo using scikit-learn pipeline",
    examples=[
        [1, "female", 28, 0, 0, 100, "C"],
        [3, "male", 22, 1, 0, 7, "S"]
    ]
)

demo.launch()